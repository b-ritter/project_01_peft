{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {
    "id": "f35354cd"
   },
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {
    "id": "560fb3ff"
   },
   "source": [
    "* PEFT technique: I went with the Lora technique since I am new to this material and could leverage some of the suggestions in the instructions.\n",
    "\n",
    "* Model: As suggested in the instructions, I used the gpt2 model since it is relatively small and useful for sequence classification.\n",
    "\n",
    "* Evaluation approach: Since my aim was to fine-tune on the AG News Dataset, I used the train split to test if the model would predict the correct class for each news snippet.\n",
    "\n",
    "* Fine-tuning dataset: In my work, I found that the 120000 samples in the AG News Dataset took too long to compute given the constraints of the Udacity GPU's. I truncated the size of this set to 1200. Likewise, I truncated the test set, also by a factor of 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {
    "id": "de8d76bb"
   },
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "I chose to use the AG News dataset for multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f551c63a",
    "outputId": "2a538707-51e8-4ec1-b68e-95e924ef6401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.25.0)\n",
      "Requirement already satisfied: packaging in /home/student/.local/lib/python3.10/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/student/.local/lib/python3.10/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/student/.local/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/student/.local/lib/python3.10/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/student/.local/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/student/.local/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/student/.local/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: pandas in /home/student/.local/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.36.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/student/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/student/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/student/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/student/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/student/.local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets peft accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b97cde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a0f7b",
   "metadata": {
    "id": "762a0f7b"
   },
   "source": [
    "## Preprocess Dataset\n",
    "Use tokenizer to preprocess text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6b55922",
   "metadata": {
    "id": "b6b55922"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b08a47",
   "metadata": {},
   "source": [
    "### Downsample Data For Training Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aee67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(dataset[\"train\"].shape[0]/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f360e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].select(range(train_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aacfebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = int(dataset[\"test\"].shape[0]/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9d95664",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = dataset[\"test\"].select(range(test_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "019b9f55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "019b9f55",
    "outputId": "dd3f5689-0809-473d-92b2-15a398bfff1e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c25f44b7b348ee8c179202818eb80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 1200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "splits = ['train', 'test']\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"text\"],  padding=\"max_length\", truncation=True, max_length=512, return_tensors='pt'), batched=True\n",
    "    )\n",
    "\n",
    "tokenized_dataset[\"train\"] = tokenized_dataset[\"train\"].rename_column('label', 'labels')\n",
    "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].rename_column('label', 'labels')\n",
    "\n",
    "tokenized_dataset[\"train\"].set_format('torch', columns=['text','labels', 'input_ids', 'attention_mask'])\n",
    "tokenized_dataset[\"test\"].set_format('torch', columns=['text','labels', 'input_ids', 'attention_mask'])\n",
    "\n",
    "print(tokenized_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7718d5f5",
   "metadata": {
    "id": "7718d5f5"
   },
   "source": [
    "## Load Pretrained Foundation Model (gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5176b07f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5176b07f",
    "outputId": "207e1461-3eae-47df-d5da-3b1be1d5e598"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "id2label = {0: \"world\", 1: \"sports\", 2: \"business\", 3: \"technology\"}\n",
    "label2id = {val: key for key, val in id2label.items()}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=4,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BROf0fzdYhqZ",
   "metadata": {
    "id": "BROf0fzdYhqZ"
   },
   "source": [
    "## Evaluate Performance of Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "GQEEoK_TYmnZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "GQEEoK_TYmnZ",
    "outputId": "4f3ce1d5-ad64-47c5-d444-982fbd10f879"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 8.146344184875488,\n",
       " 'eval_accuracy': 0.2236842105263158,\n",
       " 'eval_runtime': 2.6209,\n",
       " 'eval_samples_per_second': 28.998,\n",
       " 'eval_steps_per_second': 3.815}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "        per_device_eval_batch_size=8\n",
    "    ),\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0756673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check_classification(text, model, class_map):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    inputs.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    return class_map.get(predicted_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b6f2489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n",
      "world\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "story = \"The Senate passed legislation Tuesday that would force TikTok’s China-based parent company to sell the social media platform under the threat of a ban, a contentious move by U.S. lawmakers that’s expected to face legal challenges and disrupt the lives of content creators who rely on the short-form video app for income.\"\n",
    "print(spot_check_classification(story, lora_model, id2label))\n",
    "\n",
    "story = \"The first glow-in-the-dark animals may have been ancient corals deep in the ocean. A new study suggests that the first animal that glowed in the dark was a coral that lived deep in the ocean about half a billion years ago.\"\n",
    "print(spot_check_classification(story, lora_model, id2label))\n",
    "\n",
    "story = \"\"\"The most distant spacecraft from Earth stopped sending back understandable data last November. Flight controllers traced the blank communication to a bad computer chip and rearranged the spacecraft’s coding to work around the trouble.\\n\n",
    "NASA’s Jet Propulsion Laboratory in Southern California declared success after receiving good engineering updates late last week. The team is still working to restore transmission of the science data.\"\"\"\n",
    "print(spot_check_classification(story, lora_model, id2label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {
    "id": "4d52a229"
   },
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "Now, we perform PEFT on the foundation model using the AG News Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5775fadf",
   "metadata": {
    "id": "5775fadf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): Linear(\n",
       "                in_features=768, out_features=2304, bias=True\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=4, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=4, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "from peft import LoraConfig\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    fan_in_fan_out=True,\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "894046c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "894046c0",
    "outputId": "caf2aca5-2207-4d7b-e1aa-50f2b8b0eac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 301,056 || all params: 124,740,864 || trainable%: 0.24134512969222338\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4d4c908",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "c4d4c908",
    "outputId": "bc779061-4304-41f2-88de-96766d0d1543"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/450 05:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.983688</td>\n",
       "      <td>0.486842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.401849</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.280887</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./data/ag_news/checkpoint-150 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/ag_news/checkpoint-300 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./data/ag_news/checkpoint-450 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=450, training_loss=2.5102053493923613, metrics={'train_runtime': 310.963, 'train_samples_per_second': 11.577, 'train_steps_per_second': 1.447, 'total_flos': 943980753715200.0, 'train_loss': 2.5102053493923613, 'epoch': 3.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/ag_news\",\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        save_strategy=\"epoch\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "nONDeHXFRqiD",
   "metadata": {
    "id": "nONDeHXFRqiD"
   },
   "outputs": [],
   "source": [
    "lora_model.save_pretrained(\"gpt-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {
    "id": "615b12c6"
   },
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "While the training loop tracks the accuracy of the trained model, let's do some spot checking here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc3a8147",
   "metadata": {
    "id": "bc3a8147"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModelForSequenceClassification\n",
    "lora_model = PeftModelForSequenceClassification.from_pretrained(lora_model,\"gpt-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1a7b8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n",
      "world\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "story = \"The Senate passed legislation Tuesday that would force TikTok’s China-based parent company to sell the social media platform under the threat of a ban, a contentious move by U.S. lawmakers that’s expected to face legal challenges and disrupt the lives of content creators who rely on the short-form video app for income.\"\n",
    "print(spot_check_classification(story, lora_model, id2label))\n",
    "\n",
    "story = \"The first glow-in-the-dark animals may have been ancient corals deep in the ocean. A new study suggests that the first animal that glowed in the dark was a coral that lived deep in the ocean about half a billion years ago.\"\n",
    "print(spot_check_classification(story, lora_model, id2label))\n",
    "\n",
    "story = \"\"\"The most distant spacecraft from Earth stopped sending back understandable data last November. Flight controllers traced the blank communication to a bad computer chip and rearranged the spacecraft’s coding to work around the trouble.\\n\n",
    "NASA’s Jet Propulsion Laboratory in Southern California declared success after receiving good engineering updates late last week. The team is still working to restore transmission of the science data.\"\"\"\n",
    "print(spot_check_classification(story, lora_model, id2label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347710ba",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b496447",
   "metadata": {},
   "source": [
    "Before fine tuning, the foundation model gave only about a 20% accuracy score on classification of the AG News Dataset. After PEFT fine tuning, the accuracy increased to about 60%, which is much better. However, given the results of the spot checks, training for longer on more data would be necessary to achieve more usable results."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
